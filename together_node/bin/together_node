#! python
import typer
from typing import Optional
from rich.prompt import Prompt
from together_node.src.model import serve_model
from together_node.src.constants import MODEL_CONFIG
from together_node.src.system import check_binary_exists, remote_download

app = typer.Typer()

@app.command()
def check():
    is_slurm = check_binary_exists("sinfo")
    print("Slurm: ", is_slurm)
    is_singularity = check_binary_exists("singularity")
    print("Singularity: ", is_singularity)
    is_docker = check_binary_exists("docker")
    print("Docker: ", is_docker)

@app.command()
def serve(
        model: str=typer.Option(..., prompt="What's the model name you want to serve?"), 
        queue: str=typer.Option(..., prompt="What's the queue name you want to serve?"),
        wd: str=typer.Option(..., prompt="What's the working directory you want to serve?"),
        docker: Optional[bool]=typer.Option(False),
        singularity: bool = typer.Option(False),
        gpus: str = typer.Option(..., prompt="GPU Specifiers (e.g., titanrtx:1)"),
        account: str = typer.Option(None),
    ):
    if docker and singularity:
        print("You can only choose one of docker or singularity")
        return
    serve_model(
        model_name=model,
        queue_name=queue,
        working_dir = wd,
        use_docker=docker,
        use_singularity=singularity,
        gpus = gpus,
        account = account,
    )
    

@app.command()
def download():
    model_name = Prompt.ask("What's the model name you want to serve?")
    remote_url = MODEL_CONFIG[model_name]["singularity_url"]
    remote_download(remote_url=remote_url, local_path="./")


@app.command()
def main():
    print("TOMA")

if __name__ == "__main__":
    app()
